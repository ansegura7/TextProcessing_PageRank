Web_NN scale_NN NLP_NN :_: a_DT case_NN study_NN on_IN url_NN word_NN breaking_NN
This_DT paper_NN uses_VBZ the_DT URL_NN word_NN breaking_NN task_NN as_IN an_DT example_NN to_TO elaborate_VB what_WP we_PRP identify_VBP as_RB crucial_JJ in_IN designing_VBG statistical_JJ natural_JJ language_NN processing_NN -LRB-_-LRB- NLP_NN -RRB-_-RRB- algorithms_NNS for_IN Web_NN scale_NN applications_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- rudimentary_JJ multilingual_JJ capabilities_NNS to_TO cope_VB with_IN the_DT global_JJ nature_NN of_IN the_DT Web_NN ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- multi-style_JJ modeling_NN to_TO handle_VB diverse_JJ language_NN styles_NNS seen_VBN in_IN the_DT Web_NN contents_NNS ,_, -LRB-_-LRB- 3_LS -RRB-_-RRB- fast_JJ adaptation_NN to_TO keep_VB pace_NN with_IN the_DT dynamic_JJ changes_NNS of_IN the_DT Web_NN ,_, -LRB-_-LRB- 4_LS -RRB-_-RRB- minimal_JJ heuristic_NN assumptions_NNS for_IN generalizability_NN and_CC robustness_NN ,_, and_CC -LRB-_-LRB- 5_CD -RRB-_-RRB- possibilities_NNS of_IN efficient_JJ implementations_NNS and_CC minimal_JJ manual_JJ efforts_NNS for_IN processing_VBG massive_JJ amount_NN of_IN data_NNS at_IN a_DT reasonable_JJ cost_NN ._.
We_PRP first_RB show_VBP that_IN the_DT state-of-the-art_JJ word_NN breaking_NN techniques_NNS can_MD be_VB unified_VBN and_CC generalized_VBN under_IN the_DT Bayesian_JJ minimum_JJ risk_NN -LRB-_-LRB- BMR_NN -RRB-_-RRB- framework_NN that_IN ,_, using_VBG a_DT Web_NN scale_NN N-gram_NN ,_, can_MD meet_VB the_DT first_JJ three_CD requirements_NNS ._.
We_PRP discuss_VBP how_WRB the_DT existing_VBG techniques_NNS can_MD be_VB viewed_VBN as_IN introducing_VBG additional_JJ assumptions_NNS to_TO the_DT basic_JJ BMR_NN framework_NN ,_, and_CC describe_VBP a_DT generic_JJ yet_CC efficient_JJ implementation_NN called_VBN word_NN synchronous_JJ beam_NN search_NN ._.
Testing_VBG the_DT framework_NN and_CC its_PRP$ implementation_NN on_IN a_DT series_NN of_IN large_JJ scale_NN experiments_NNS reveals_VBZ the_DT following_NN ._.
First_RB ,_, the_DT language_NN style_NN used_VBN to_TO build_VB the_DT model_NN plays_VBZ a_DT critical_JJ role_NN in_IN the_DT word_NN breaking_NN task_NN ,_, and_CC the_DT most_RBS suitable_JJ for_IN the_DT URL_NN word_NN breaking_NN task_NN appears_VBZ to_TO be_VB that_DT of_IN the_DT document_NN title_NN where_WRB the_DT best_JJS performance_NN is_VBZ obtained_VBN ._.
Models_NNS created_VBN from_IN other_JJ language_NN styles_NNS ,_, such_JJ as_IN from_IN document_NN body_NN ,_, anchor_NN text_NN ,_, and_CC even_RB queries_NNS ,_, exhibit_VBP varying_VBG degrees_NNS of_IN mismatch_NN ._.
Although_IN all_DT styles_NNS benefit_VBP from_IN increasing_VBG modeling_NN power_NN which_WDT ,_, in_IN our_PRP$ experiments_NNS ,_, corresponds_VBZ to_TO the_DT use_NN of_IN a_DT higher_JJR order_NN N-gram_NN ,_, the_DT gain_NN is_VBZ most_RBS recognizable_JJ for_IN the_DT title_NN model_NN ._.
The_DT heuristics_NNS proposed_VBN by_IN the_DT prior_JJ arts_NNS do_VBP contribute_VB to_TO the_DT word_NN breaking_NN performance_NN for_IN mismatched_VBN or_CC less_RBR powerful_JJ models_NNS ,_, but_CC are_VBP less_RBR effective_JJ and_CC ,_, in_IN many_JJ cases_NNS ,_, lead_VBP to_TO poorer_JJR performance_NN than_IN the_DT matched_JJ model_NN with_IN minimal_JJ assumptions_NNS ._.
For_IN the_DT matched_JJ model_NN based_VBN on_IN document_NN titles_NNS ,_, an_DT accuracy_NN rate_NN of_IN 97.18_CD %_NN can_MD already_RB be_VB achieved_VBN using_VBG simple_JJ trigram_NN without_IN any_DT heuristics_NNS ._.
