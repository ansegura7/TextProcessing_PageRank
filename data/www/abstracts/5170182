Performance_NNP of_IN compressed_VBN inverted_JJ list_NN caching_NN in_IN search_NN engines_NNS
Due_JJ to_TO the_DT rapid_JJ growth_NN in_IN the_DT size_NN of_IN the_DT web_NN ,_, web_NN search_NN engines_NNS are_VBP facing_VBG enormous_JJ performance_NN challenges_NNS ._.
The_DT larger_JJR engines_NNS in_IN particular_JJ have_VBP to_TO be_VB able_JJ to_TO process_VB tens_NNS of_IN thousands_NNS of_IN queries_NNS per_IN second_NN on_IN tens_NNS of_IN billions_NNS of_IN documents_NNS ,_, making_VBG query_JJ throughput_NN a_DT critical_JJ issue_NN ._.
To_TO satisfy_VB this_DT heavy_JJ workload_NN ,_, search_NN engines_NNS use_VBP a_DT variety_NN of_IN performance_NN optimizations_NNS including_VBG index_NN compression_NN ,_, caching_NN ,_, and_CC early_JJ termination_NN ._.
We_PRP focus_VBP on_IN two_CD techniques_NNS ,_, inverted_JJ index_NN compression_NN and_CC index_NN caching_NN ,_, which_WDT play_VBP a_DT crucial_JJ rule_NN in_IN web_NN search_NN engines_NNS as_RB well_RB as_IN other_JJ high-performance_JJ information_NN retrieval_NN systems_NNS ._.
We_PRP perform_VBP a_DT comparison_NN and_CC evaluation_NN of_IN several_JJ inverted_JJ list_NN compression_NN algorithms_NNS ,_, including_VBG new_JJ variants_NNS of_IN existing_VBG algorithms_NNS that_WDT have_VBP not_RB been_VBN studied_VBN before_RB ._.
We_PRP then_RB evaluate_VBP different_JJ inverted_JJ list_NN caching_NN policies_NNS on_IN large_JJ query_NN traces_NNS ,_, and_CC finally_RB study_VB the_DT possible_JJ performance_NN benefits_NNS of_IN combining_VBG compression_NN and_CC caching_NN ._.
The_DT overall_JJ goal_NN of_IN this_DT paper_NN is_VBZ to_TO provide_VB an_DT updated_VBN discussion_NN and_CC evaluation_NN of_IN these_DT two_CD techniques_NNS ,_, and_CC to_TO show_VB how_WRB to_TO select_VB the_DT best_JJS set_NN of_IN approaches_NNS and_CC settings_NNS depending_VBG on_IN parameter_NN such_JJ as_IN disk_NN speed_NN and_CC main_JJ memory_NN cache_NN size_NN ._.
